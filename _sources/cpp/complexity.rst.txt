*******************
Complexity Analysis
*******************

Analyze the computational resources consumed by an algorithm. Limited to the
imperative programming paradigm in the course.

Concepts
========

.. glossary::

  Computational complexity
    The computational resources consumed by an algorithm as a function of the
    size of the problem.

  Time complexity
    The computational time consumed by an algorithm a function of the size of
    the problem. It is usually described using a function :math:`T(N)`.

  Space complexity
    The computational storage space (usually refer to memory) consumed by an
    algorithm a function of the size of the problem. **auxiliary space
    complexity** is the space complexity excluding the input data. It is usually
    described using a function :math:`S(N)`.

  Best case, worst case, and average case
    Best case is the scenario in which the algorithm finished with the least
    resource consumed. Worst case is the scenario in which the algorithm
    finished with the most resource consumed. Sometimes we will use average
    case, which is the average over all possible inputs.

  Constant time operation
    Because the accurate measurement of time consumption is impossible, we
    usually count the number of constant time operations to estimate the time
    consumption. A constant time operation is an operation that always consume a
    certain amount of time regardless of the problem size N.

  Growth rate
    How much more resource is needed when the problem size grows. It is usually
    described using simple math functions. It is a simple way to visualize the
    complexity.

  Asymptotic notation
    The math language we use to describe the complexity in a formal way. It
    includes :math:`O` (big-O), :math:`\Omega` (big-omega), :math:`\Theta`
    (big-theta) notations.

  Lower bound
    The best (least resource) complexity of a given algorithm. Related to the best case and the :math:`\Omega` (big-omega) notation.

  Upper bound
    The worst (most resource) complexity of a given algorithm. Related to the worst case and the :math:`O` (big-O) notation.

  Exact bound
    When a same complexity can be found for both the upper and lower bound, it
    is the exact bound :math:`\Theta`

.. image:: /_static/complexity.png
  :width: 400
  :alt: Complexity
  :align: center


.. list-table:: Common Growth Rates :math:`f(N)` (least to most complex)
  :header-rows: 1
  :widths: 20 40

  * - Name
    - Description
  * - :math:`1`
    - constant
  * - :math:`log(N)`
    - logarithmic
  * - :math:`n`
    - linear
  * - :math:`Nlog(N)`
    - linear logarithmic
  * - :math:`n^2`
    - quadratic
  * - :math:`n^3`
    - cubic
  * - :math:`2^n`
    - exponential
  * - :math:`n!`
    - factorial

.. note::

  Time complexity is more useful and is focused in the following sections. Most
  of the rules can be used with space complexity with little modification.

Asymptotic notation
===================

A.k.a Bachmannâ€“Landau notation. A mathematical notation system to describe the
limiting behavior of a function.

Formal Definitions
------------------

Given :math:`T(N)` the time function of the problem size :math:`N`

We will write :math:`T(N) = O(f(N))` or :math:`T(N) \in O(f(N))` if there
exists a certain positive constant :math:`c` and a problem size :math:`n_{0}`,
such that :math:`T(N) \leq cf(N)` for all :math:`N \geq n_{0}`.

We will write :math:`T(N) = \Omega(f(N))` or :math:`T(N) \in \Omega(f(N))` if
there exists a certain positive constant :math:`c` and a problem size
:math:`n_{0}`, such that :math:`T(N) \geq cf(N)` for all :math:`N \geq n_{0}`.

We will write :math:`T(N) = \Theta(f(N))` if :math:`T(N) = \Omega(f(N))` and
:math:`T(N) = O(f(N))` are both true. Note: the constants are different.

.. warning::

  The :math:`=` used in equations like :math:`T(N) = O(f(N))` does not mean
  *equal*! It means *in* or *belong to*.

The notations :math:`O(f(N))`, :math:`\Omega(f(N))`, and
:math:`T(N) = \Theta(f(N))` define sets of functions that have the same
*order*. Thus, the set will be the same of the function :math:`f(N)` has the
same order. For example, :math:`O(N^2)=O(2*N^2)=O(N^2+3N)=\dots`

Analysis
========
Find :math:`T(N)`
-----------------

+ additive (sequential, branch)
+ multiplicative (loop, recursion)

  * complexity of number of iterations

    - how problem size is reduced in each iteration`
    - reduce by half each round: :math:`O(log(N))`
    - reduce by a constant each round: :math:`O(N)`

  * complexity in each iteration

Find :math:`O` given :math:`T(N)`
---------------------------------

Given :math:`T(N) = 20 * N^2 + 10 * N + 12`, find the term with highest order,
and remove all constant factors to give :math:`O(N^2)`

Pitfalls
========

+ Confusing :math:`T(N)` to :math:`O(f(N))`
+ Not all function calls are constant time operations (a.k.a. :math:`O(1)`)
