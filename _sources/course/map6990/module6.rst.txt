.. highlight:: c++
  :linenothreshold: 5

**************************************
Module 6: Data Analysis for Big Data 2
**************************************

Machine Learning
================
Types of learning tasks
-----------------------
+ Supervised Learning:

  Supervised learning is a type of learning task that involves the use of
  labeled data, where the algorithm is trained using inputs and corresponding
  outputs. It can be further divided into two categories:

  * Classification: Classification is a type of supervised learning where the
    algorithm learns to predict a discrete output. For example, predicting
    whether an email is spam or not.

  * Regression: Regression is a type of supervised learning where the algorithm
    learns to predict a continuous output. For example, predicting the price of
    a house.

+ Unsupervised Learning:

  Unsupervised learning is a type of learning task that involves the use of
  unlabeled data. In this type of learning, the algorithm learns patterns and
  relationships within the data without any specific guidance or target output.
  It can be further divided into three categories:

  * Clustering: Clustering is a type of unsupervised learning where the
    algorithm groups similar data points together. For example, grouping
    customers based on their purchase history.

  * Dimension reduction: Dimension reduction is a type of unsupervised learning
    where the algorithm reduces the number of variables in the data while
    preserving its underlying structure. For example, reducing the number of
    variables in an image while preserving its visual features. It can also be
    employed to visualize data in 2D and 3D plots.

+ Reinforcement Learning:

  Reinforcement learning is a type of learning task where an agent learns to
  interact with an environment to achieve a specific goal. The agent receives
  rewards or punishments based on its actions and learns to make optimal
  decisions to maximize the cumulative reward.

+ Semi-Supervised Learning:

  Semi-supervised learning is a type of learning task that involves the use of
  both labeled and unlabeled data. In this type of learning, the algorithm
  learns from the labeled data and uses the unlabeled data to improve its
  performance.

+ Self-Supervised Learning:

  Self-supervised learning is a type of learning task that involves the use of
  labeled data generated by the algorithm itself. In this type of learning, the
  algorithm creates a task based on the input data, and the output is used as
  the label for the same input data. For example, predicting the missing pixels
  in an image.

  Self-Supervised learning is extensively used in deep learning training.

+ Ensemble Learning

  These models combine multiple machine learning models to improve performance.
  Examples of ensemble learning models include bagging, boosting, and stacking.

+ Transfer learning

  Transfer learning is a machine learning technique where knowledge gained from
  training a model on one task is leveraged to improve the performance on a
  new, related task. Rather than starting the learning process from scratch,
  transfer learning enables the reuse of pre-trained models, which can save
  time and computational resources while also improving the accuracy of the new
  model. The pre-trained model's learned features and representations can be
  fine-tuned on the new data or used to extract useful features that are then
  fed into a new model. Transfer learning has been widely used in many domains,
  such as computer vision, natural language processing, and speech recognition,
  and has proven to be an effective way to tackle many real-world problems with
  limited labeled data.

Traditional Machine Learning Models
-----------------------------------
+ Supervised learning

  * Linear Regression
  * Logistic Regression
  * Support Vector Machine

+ Unsupervised learning

  * K-means clustering
  * Principal Component Analysis (PCA)

+ Reinforcement learning

  * Q-learning

.. image:: /_static/ml-map.png
  :alt: Scikit Learning Choosing the Right Estimator

.. container:: footnote

  Credit: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html

Deep Learning
=============
Deep learning models are a type of machine learning algorithm that are based on
artificial neural networks with multiple layers. These models have gained
popularity in recent years due to their ability to automatically learn
representations of data and extract features from high-dimensional inputs such
as images, audio, and text.

Characteristics of deep learning models
---------------------------------------
+ Ability to learn complex representations: Deep learning models are able to
  learn complex representations of data by stacking multiple layers of neurons
  on top of each other. This enables them to extract high-level features from
  raw input data.
+ Automatic feature extraction: Deep learning models can automatically extract
  features from raw data, which eliminates the need for manual feature
  engineering.
+ Large amounts of data: Deep learning models require large amounts of data to
  train effectively due to their large number of parameters.
+ Computationally intensive: Deep learning models require significant
  computational resources, including powerful hardware and efficient
  algorithms, to train and run.

Compare to traditional machine learning models
----------------------------------------------
+ Data representation: Traditional machine learning models typically rely on
  handcrafted feature engineering to extract relevant information from raw
  data. In contrast, deep learning models can automatically learn
  representations of data and extract features from high-dimensional inputs.
+ Complexity: Traditional machine learning models are typically based on simple
  models such as linear regression or decision trees, which are not well-suited
  for handling complex data. Deep learning models, on the other hand, are based
  on neural networks with multiple layers, which are capable of learning
  complex representations of data.
+ Performance: Deep learning models have achieved state-of-the-art performance
  on various tasks, such as image recognition and natural language processing,
  and have surpassed traditional machine learning models in many cases.
+ Data requirements: Deep learning models typically require large amounts of
  labeled data to train effectively, whereas traditional machine learning
  models can often work with smaller datasets.

Deep learning models
--------------------
Deep learning models are more complex than traditional machine learning models.
Thus, the categorization of deep learning models is more complex than that of
traditional machine learning models. Deep learning models can be categorized
based on the type of learning task, the type of neural network architecture,
and the type of learning algorithm. The following table lists some of the most
popular deep learning models.

+ Supervised learning

  * Convolutional Neural Network (CNN)
  * Recurrent Neural Network (RNN)
  * Generative Adversarial Network (GAN)

+ Unsupervised learning

  * Autoencoder
  * Diffusion models
  * Generative Adversarial Network (GAN)

+ Reinforcement learning

  * Deep Q-Network (DQN)

They can also be categorized by the data they are designed to process:

+ Computer vision

  * Convolutional Neural Network (CNN)
  * Recurrent Neural Network (RNN)
  * Generative Adversarial Network (GAN)
  * Diffusion models

+ Natural language processing

  * Transformer models
  * Matrix Factorization
  * Recurrent Neural Network (RNN)

+ Time-series data

  * Example: sound, speech, video, stock market data, etc.
  * Recurrent Neural Network (RNN)
  * Convolutional Neural Network (CNN)

Trending Deep Learning Models
-----------------------------
The AI models are booming since the publication of ChatGPT in 2022. Now it
become a field of big companies, big organizations and some research
institutes. It is not possible for any small institute and individuals to train
these models from scratch. Researchers and application developers are more
interested to develop based on the pre-trained models from these organizations
or even based on the APIs provided by them. They employ either fine-tuning or
few-shot learning to adapt the pre-trained models to their specific tasks.

+ Large language models (LLM)

  Large language models are a type of transformer model that are trained on
  large amounts of text data. They are capable of generating coherent text
  based on a given prompt. They can also be used to perform various NLP tasks
  such as question answering, text summarization, and machine translation.

  * GPT family from OpenAI: GPT-3, GPT-4, ChatGPT
  * Google BERT, Palm, T5, Bard
  * Facebook RoBERTa, BigBird
  * BigScience BLOOM

+ Image generation models

  * OpenAI DALL-E
  * Stable Diffusion
  * MidJourney (possibly related to stable diffusion)

+ Voice/Speech models

  * Google WaveNet, Universal Speech Model (USM)
  * OpenAI Whisper
