{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module 4: PySpark Programming For Biginners\n"
      ],
      "metadata": {
        "id": "nZHxhrB6RSfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize"
      ],
      "metadata": {
        "id": "a0teY5ZOR2VF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrf3m7auROVz"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark Context\n",
        "sc = SparkSession.builder.master(\"local[*]\").appName(\"Test\").getOrCreate().sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python \n",
        "### Lambda function examples\n",
        "In the demonstration, the **map** function takes a function and a list as parameters. It will apply the function to each element in the list to give a new list.\n",
        "\n",
        "The **reduce** function takes a function and a list as parameters. It will apply the function repeatedly to the element in the list. It will aggregate values in a list to give a single value.\n",
        "\n",
        "The result is converted to list for printint. "
      ],
      "metadata": {
        "id": "Wt7vurx8SBMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Square function\n",
        "l1 = [1, 2, 3]\n",
        "print(list(\n",
        "    map(lambda x: x*x, l1)\n",
        "    ))\n",
        "\n",
        "# Split line to words, space as delimiter\n",
        "lines = ['line 1 text', 'line 2 text']\n",
        "print(list(\n",
        "    map(lambda line: line.split(), lines)\n",
        "    ))\n",
        "\n",
        "# Split multi-line text into lines\n",
        "paragraphs = [\n",
        "''' paragraph 1\n",
        "line 1''',\n",
        "''' paragraph 2.\n",
        "line 2'''\n",
        "]\n",
        "print(list(\n",
        "    map(lambda paragraph: paragraph.split('\\n'), paragraphs)\n",
        "    ))\n",
        "\n",
        "# Words to key-value pairs\n",
        "words = ['apple', 'sheep', 'peach', 'wolf']\n",
        "print(list(\n",
        "    map(lambda word: (word, 1), words)\n",
        "))\n",
        "\n",
        "# Get first/second elements from pairs\n",
        "pairs = [('apple', 1), ('sheep', 1), ('peach', 1), ('wolf', 1)]\n",
        "print(list(\n",
        "    map(lambda p: p[0], pairs)\n",
        "))\n",
        "print(list(\n",
        "    map(lambda p: p[1], pairs)\n",
        "))\n"
      ],
      "metadata": {
        "id": "0kuI5izxSJ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "#Reduce by add\n",
        "l1 = [1, 3, 5, 7]\n",
        "print(\n",
        "    reduce(lambda a, b: a+b, l1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "PLpxelZDVMMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RDD"
      ],
      "metadata": {
        "id": "PgjM_3NNXAsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([\n",
        "    1, 2, 3, 4\n",
        "])\n",
        "squared = rdd.map(lambda x: x*x)\n",
        "print(squared.collect())  # Get all\n",
        "print(squared.take(3))  # Get the first three\n",
        "print(squared.first())\n",
        "print(squared.count())\n",
        "print(squared.sum())\n",
        "print(squared.mean())\n",
        "print(squared.min())\n",
        "print(squared.max())"
      ],
      "metadata": {
        "id": "_CpJXA9OXN-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''word count from Wikipedia the free encyclopedia\n",
        "the word count is the number of words in a document or passage of text Word counting may be needed when a text\n",
        "is required to stay within certain numbers of words This may particularly be the case in academia legal\n",
        "proceedings journalism and advertising Word count is commonly used by translators to determine the price for\n",
        "the translation job Word counts may also be used to calculate measures of readability and to measure typing\n",
        "and reading speeds usually in words per minute When converting character counts to words a measure of five or\n",
        "six characters to a word is generally used Contents Details and variations of definition Software In fiction\n",
        "In non fiction See also References Sources External links Details and variations of definition\n",
        "This section does not cite any references or sources Please help improve this section by adding citations to\n",
        "reliable sources Unsourced material may be challenged and removed\n",
        "Variations in the operational definitions of how to count the words can occur namely what counts as a word and\n",
        "which words don't count toward the total However especially since the advent of widespread word processing there\n",
        "is a broad consensus on these operational definitions and hence the bottom line integer result\n",
        "The consensus is to accept the text segmentation rules generally found in most word processing software including how\n",
        "word boundaries are determined which depends on how word dividers are defined The first trait of that definition is that a space any of various whitespace\n",
        "characters such as a regular word space an em space or a tab character is a word divider Usually a hyphen or a slash is too\n",
        "Different word counting programs may give varying results depending on the text segmentation rule\n",
        "details and on whether words outside the main text such as footnotes endnotes or hidden text) are counted But the behavior\n",
        "of most major word processing applications is broadly similar However during the era when school assignments were done in\n",
        "handwriting or with typewriters the rules for these definitions often differed from todays consensus\n",
        "Most importantly many students were drilled on the rule that certain words don't count usually articles namely a an the but\n",
        "sometimes also others such as conjunctions for example and or but and some prepositions usually to of Hyphenated permanent\n",
        "compounds such as follow up noun or long term adjective were counted as one word To save the time and effort of counting\n",
        "word by word often a rule of thumb for the average number of words per line was used such as 10 words per line These rules\n",
        "have fallen by the wayside in the word processing era the word count feature of such software which follows the text\n",
        "segmentation rules mentioned earlier is now the standard arbiter because it is largely consistent across documents and\n",
        "applications and because it is fast effortless and costless already included with the application As for which sections of\n",
        "a document count toward the total such as footnotes endnotes abstracts reference lists and bibliographies tables figure\n",
        "captions hidden text the person in charge teacher client can define their choice and users students workers can simply\n",
        "select or exclude the elements accordingly and watch the word count automatically update Software Modern web browsers\n",
        "support word counting via extensions via a JavaScript bookmarklet or a script that is hosted in a website Most word\n",
        "processors can also count words Unix like systems include a program wc specifically for word counting\n",
        "As explained earlier different word counting programs may give varying results depending on the text segmentation rule\n",
        "details The exact number of words often is not a strict requirement thus the variation is acceptable\n",
        "In fiction Novelist Jane Smiley suggests that length is an important quality of the novel However novels can vary\n",
        "tremendously in length Smiley lists novels as typically being between and words while National Novel Writing Month\n",
        "requires its novels to be at least words There are no firm rules for example the boundary between a novella and a novel\n",
        "is arbitrary and a literary work may be difficult to categorise But while the length of a novel is to a large extent up\n",
        "to its writer lengths may also vary by subgenre many chapter books for children start at a length of about words and a\n",
        "typical mystery novel might be in the to word range while a thriller could be over words\n",
        "The Science Fiction and Fantasy Writers of America specifies word lengths for each category of its Nebula award categories\n",
        "Classification\tWord count Novel over words Novella to words Novelette to words Short story under words\n",
        "In non fiction The acceptable length of an academic dissertation varies greatly dependent predominantly on the subject\n",
        "Numerous American universities limit Ph.D. dissertations to at most words barring special permission for exceeding this limit\n",
        "'''\n",
        "\n",
        "# Split by new line character and parallelize\n",
        "lines = sc.parallelize(text.split('\\n'))\n",
        "print(\"collection of lines:\")\n",
        "print(lines.collect())\n",
        "\n",
        "# map to list of words\n",
        "words = lines.map(lambda line: line.split())\n",
        "print(\"\\ncollection of words, not flattened:\")\n",
        "print(words.collect())\n",
        "\n",
        "# Flap map to lower case words\n",
        "words = lines.flatMap(lambda line: line.split()).map(lambda word: word.lower())\n",
        "print(\"\\ncollection of words, flattened:\")\n",
        "print(words.collect())\n",
        "print('\\ncounts of words')\n",
        "counts = words.countByValue()\n",
        "print(counts)\n",
        "\n",
        "# words to pairs\n",
        "pairs = words.map(lambda word: (word, 1))\n",
        "print('\\ncollection of pairs')\n",
        "print(pairs.collect())"
      ],
      "metadata": {
        "id": "ruoMO8DMXq53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = sc.parallelize([\n",
        "    ('dog', 1), ('cat', 1), ('dog', 3), ('cat', 5), ('fish', 1)\n",
        "])\n",
        "counts = pairs.countByKey()  # count the occurance of keys\n",
        "print(counts)\n",
        "counts = pairs.reduceByKey(lambda a, b: a + b)  # sum the counts of each keys\n",
        "print(counts.collect())"
      ],
      "metadata": {
        "id": "relu3qmldhhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}